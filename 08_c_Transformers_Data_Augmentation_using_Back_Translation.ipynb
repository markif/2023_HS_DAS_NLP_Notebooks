{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\" src=\"https://www.fhnw.ch/de/++theme++web16theme/assets/media/img/fachhochschule-nordwestschweiz-fhnw-logo.svg\" alt=\"FHNW Logo\">\n",
    "\n",
    "\n",
    "# Data Augmentation using Back Translation\n",
    "\n",
    "by Fabian Märki\n",
    "\n",
    "## Summary\n",
    "The aim of this notebook is to show how Huggingface's model can be used for back translation.\n",
    "\n",
    "### Sources\n",
    "- [Text Data Augmentation with Back Translation](https://amitness.com/back-translation/)\n",
    "- [Faster batch translation](https://github.com/huggingface/transformers/issues/9994) with code example\n",
    "\n",
    "### Libraries/Models\n",
    "- [Hugging Face](https://huggingface.co)\n",
    "- [Translation Models](https://huggingface.co/models?language=de&pipeline_tag=translation&sort=downloads&search=Helsinki-NLP) that can be used with this code\n",
    "\n",
    "## Links\n",
    "- [Enabling GPU on Google Colab](https://www.tutorialspoint.com/google_colab/google_colab_using_free_gpu.htm)\n",
    "\n",
    "This notebook contains assigments: <font color='red'>Questions are written in red.</font>\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/markif/2023_HS_DAS_NLP_Notebooks/blob/master/08_c_Transformers_Data_Augmentation_using_Back_Translation.ipynb\">\n",
    "  <img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install 'fhnw-nlp-utils>=0.8.0,<0.9.0'\n",
    "\n",
    "from fhnw.nlp.utils.processing import parallelize_dataframe\n",
    "from fhnw.nlp.utils.processing import is_iterable\n",
    "from fhnw.nlp.utils.storage import download\n",
    "from fhnw.nlp.utils.storage import save_dataframe\n",
    "from fhnw.nlp.utils.storage import load_dataframe\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure that a GPU is available (see [here](https://www.tutorialspoint.com/google_colab/google_colab_using_free_gpu.htm))!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS name: posix\n",
      "Platform name: Linux\n",
      "Platform release: 5.15.0-48-generic\n",
      "Python version: 3.6.9\n",
      "CPU cores: 6\n",
      "RAM: 31.12GB total and 23.46GB available\n",
      "Tensorflow version: 2.5.1\n",
      "GPU is available\n",
      "GPU is a NVIDIA GeForce RTX 2070 with Max-Q Design with 8192MiB\n"
     ]
    }
   ],
   "source": [
    "from fhnw.nlp.utils.system import set_log_level\n",
    "from fhnw.nlp.utils.system import system_info\n",
    "\n",
    "set_log_level()\n",
    "print(system_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.69 s, sys: 1.55 s, total: 9.24 s\n",
      "Wall time: 5.26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(350087, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "download(\"https://drive.switch.ch/index.php/s/0hE8wO4FbfGIJld/download\", \"data/german_doctor_reviews_tokenized.parq\")\n",
    "data = load_dataframe(\"data/german_doctor_reviews_tokenized.parq\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>token_lemma</th>\n",
       "      <th>token_stem</th>\n",
       "      <th>token_clean_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[ich, bin, franzose, und, bin, seit, ein, paar...</td>\n",
       "      <td>ich bin franzose und bin seit ein paar wochen ...</td>\n",
       "      <td>[franzose, seit, paar, wochen, muenchen, zahn,...</td>\n",
       "      <td>[franzos, seit, paar, woch, muench, ., zahn, s...</td>\n",
       "      <td>[franzose, seit, paar, wochen, muenchen, ., za...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>[dieser, arzt, ist, das, unmöglichste, was, mi...</td>\n",
       "      <td>dieser arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnen, unfr...</td>\n",
       "      <td>[arzt, unmog, leb, je, begegnet, unfreund, ,, ...</td>\n",
       "      <td>[arzt, unmöglichste, leben, je, begegnet, unfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>[hatte, akute, beschwerden, am, rücken, ., her...</td>\n",
       "      <td>hatte akute beschwerden am rücken . herr magur...</td>\n",
       "      <td>[akut, beschwerden, rücken, magura, erste, arz...</td>\n",
       "      <td>[akut, beschwerd, ruck, ., magura, erst, arzt,...</td>\n",
       "      <td>[akute, beschwerden, rücken, ., magura, erste,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_original  rating  \\\n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...     2.0   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...     1.0   \n",
       "\n",
       "                                                text     label  sentiment  \\\n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...  positive          1   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...  negative         -1   \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...  positive          1   \n",
       "\n",
       "                                         token_clean  \\\n",
       "0  [ich, bin, franzose, und, bin, seit, ein, paar...   \n",
       "1  [dieser, arzt, ist, das, unmöglichste, was, mi...   \n",
       "2  [hatte, akute, beschwerden, am, rücken, ., her...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  ich bin franzose und bin seit ein paar wochen ...   \n",
       "1  dieser arzt ist das unmöglichste was mir in me...   \n",
       "2  hatte akute beschwerden am rücken . herr magur...   \n",
       "\n",
       "                                         token_lemma  \\\n",
       "0  [franzose, seit, paar, wochen, muenchen, zahn,...   \n",
       "1  [arzt, unmöglichste, leben, je, begegnen, unfr...   \n",
       "2  [akut, beschwerden, rücken, magura, erste, arz...   \n",
       "\n",
       "                                          token_stem  \\\n",
       "0  [franzos, seit, paar, woch, muench, ., zahn, s...   \n",
       "1  [arzt, unmog, leb, je, begegnet, unfreund, ,, ...   \n",
       "2  [akut, beschwerd, ruck, ., magura, erst, arzt,...   \n",
       "\n",
       "                               token_clean_stopwords  \n",
       "0  [franzose, seit, paar, wochen, muenchen, ., za...  \n",
       "1  [arzt, unmöglichste, leben, je, begegnet, unfr...  \n",
       "2  [akute, beschwerden, rücken, ., magura, erste,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the computed columns (will need to be re-computed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"token_clean\", \"token_lemma\", \"token_stem\", \"token_clean_stopwords\", \"text_clean\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Ich bin franzose und bin seit ein paar Wochen ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hatte akute Beschwerden am Rücken. Herr Magura...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_original  rating  \\\n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...     2.0   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...     1.0   \n",
       "\n",
       "                                                text     label  sentiment  \n",
       "0  Ich bin franzose und bin seit ein paar Wochen ...  positive          1  \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...  negative         -1  \n",
       "2  Hatte akute Beschwerden am Rücken. Herr Magura...  positive          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep negative text (the class with fewer samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33022, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augm = data[data[\"label\"] == \"negative\"]\n",
    "data_augm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1. Termin:&lt;br /&gt;\\n1 Stunde Wartezimmer + 2 min...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>. Termin Stunde Wartezimmer minütige Behandlu...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Eine sehr unfreundliche Ärztin, so etwas habe ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Eine sehr unfreundliche Ärztin, so etwas habe ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_original  rating  \\\n",
       "1   Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "13  1. Termin:<br />\\n1 Stunde Wartezimmer + 2 min...     6.0   \n",
       "19  Eine sehr unfreundliche Ärztin, so etwas habe ...     6.0   \n",
       "\n",
       "                                                 text     label  sentiment  \n",
       "1   Dieser Arzt ist das unmöglichste was mir in me...  negative         -1  \n",
       "13   . Termin Stunde Wartezimmer minütige Behandlu...  negative         -1  \n",
       "19  Eine sehr unfreundliche Ärztin, so etwas habe ...  negative         -1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_augm = data_augm.reset_index(drop=True)\n",
    "data_augm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!pip install torch transformers sentencepiece mosestokenizer sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compute_device():\n",
    "    \"\"\"Provides the device for the computation\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The GPU device with number (cuda:0) or cpu\n",
    "    \"\"\"\n",
    "    \n",
    "    import torch\n",
    "\n",
    "    return \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def gpu_empty_cache():\n",
    "    \"\"\"Cleans the GPU cache which seems to fill up after a while\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    import torch\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"verbose\": True,\n",
    "    \"shuffle\": True,\n",
    "    # modify batch_size in case you experience memory issues\n",
    "    \"batch_size\": 8,\n",
    "    \"X_column_name\": \"text\",\n",
    "    \"y_column_name\": \"label\",\n",
    "    \"y_column_name_prediction\": \"translation\",\n",
    "    \"last_stored_batch\": -1,\n",
    "    \"store_path\": \"data/german_doctor_reviews_augmented_translated.parq\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Translation\n",
    "\n",
    "You might repeate following steps for several languages (see [here](https://huggingface.co/models?language=de&pipeline_tag=translation&sort=downloads&search=Helsinki-NLP) for alternative models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**TASK: Try a different language by replacing `lang_to` with another from the [Helsinki-NLP/opus-mt-...](https://huggingface.co/models?language=de&pipeline_tag=translation&sort=downloads&search=Helsinki-NLP) list.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b620f8c4fb484ca5ab95355bcd068b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/809k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5318993981e74b32a637d5cd8d8992a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/799k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd127151cbd4560816955ff6a894143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08af3291eafd475989e838c832cd5ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b189b9dcd547a6947770e2c83089ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96de76e9fbd34b5884146d8ec38e65ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c624df048ca461a83c693dbfa192de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/799k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b670536148f14443b2e5fe09f6c99c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/809k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6de97b07234926bb1a3801b97ea1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548631249386429ba1e536412466a422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3ee8360a8e4a129cfdb33381529949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ef0b88aaff40d594c5a392458f35c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/290M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# replace values to load different tranlsation models\n",
    "lang_from = \"de\"\n",
    "lang_to = \"es\"\n",
    "compute_device = get_compute_device()\n",
    "\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "orig2dest_model_name = \"Helsinki-NLP/opus-mt-\"+lang_from+\"-\"+lang_to\n",
    "orig2dest_tokenizer = MarianTokenizer.from_pretrained(orig2dest_model_name)\n",
    "orig2dest_model = MarianMTModel.from_pretrained(orig2dest_model_name).to(compute_device)\n",
    "dest2orig_model_name = \"Helsinki-NLP/opus-mt-\"+lang_to+\"-\"+lang_from\n",
    "dest2orig_tokenizer = MarianTokenizer.from_pretrained(dest2orig_model_name)\n",
    "dest2orig_model = MarianMTModel.from_pretrained(dest2orig_model_name).to(compute_device)\n",
    "\n",
    "#from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
    "#orig2dest_model_name = \"facebook/wmt19-\"+lang_from+\"-\"+lang_to\n",
    "#orig2dest_tokenizer = FSMTTokenizer.from_pretrained(orig2dest_model_name)\n",
    "#orig2dest_model = FSMTForConditionalGeneration.from_pretrained(orig2dest_model_name).to(device)\n",
    "#dest2orig_model_name = \"facebook/wmt19-\"+lang_to+\"-\"+lang_from\n",
    "#dest2orig_tokenizer = FSMTTokenizer.from_pretrained(dest2orig_model_name)\n",
    "#dest2orig_model = FSMTForConditionalGeneration.from_pretrained(dest2orig_model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**TASK: Print the intermediate translations (i.e. decode the `tokenized_dest_texts`) in order to get an understanding of the *creative power* of the back translation (you might want to choose a language you understand).**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translate(params, texts):\n",
    "    #tokenized_texts = orig2dest_tokenizer.prepare_seq2seq_batch(texts, return_tensors=\"pt\").to(compute_device)\n",
    "    tokenized_texts = orig2dest_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(compute_device)\n",
    "    back_translations = [set() for _ in range(len(texts))]\n",
    "\n",
    "    # Translate texts to target language (e.g. Spanish) and back to source language (e.g. German)\n",
    "    generate_kwargs = {\"num_beams\": 1, \"do_sample\": True, \"num_return_sequences\": 2}\n",
    "    tokenized_dest_texts = orig2dest_model.generate(tokenized_texts[\"input_ids\"], attention_mask=tokenized_texts[\"attention_mask\"], top_p=0.7, **generate_kwargs)\n",
    "    tokenized_source_texts = dest2orig_model.generate(tokenized_dest_texts, top_p=0.8, **generate_kwargs)\n",
    "    \n",
    "    # TODO: !!! place your code here !!!\n",
    "    ####################################\n",
    "\n",
    "    #for i, t in enumerate(tokenized_dest_texts):\n",
    "    #    print(orig2dest_tokenizer.decode(t, skip_special_tokens=True).lower())\n",
    "        \n",
    "    ###################\n",
    "    # TODO: !!! end !!!\n",
    "\n",
    "    # Decode and deduplicate back-translations and assign to original text indices\n",
    "    for i, t in enumerate(tokenized_source_texts):\n",
    "        back_translations[i // 4].add(dest2orig_tokenizer.decode(t, skip_special_tokens=True).lower())\n",
    "\n",
    "    # Remove back translations that are empty or equal to the original text\n",
    "    return [[bt for bt in s if bt and bt != t] for s, t in zip(back_translations, map(str.lower, texts))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give it a try..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['- hey, wie geht es ihnen?',\n",
       "  'hey, wie geht es euch?',\n",
       "  \"wie geht's heute?\",\n",
       "  'wie geht es ihnen heute?'],\n",
       " ['die ntp ist doch super, oder?',\n",
       "  '- ist das nlp ein großartiger ort?',\n",
       "  'die nhp ist wirklich cool, oder?',\n",
       "  '- ist die nlp ein großartiger ort?']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_translate(params, [\"Hallo zusammen! Wie geht es euch heute?\", \"NLP ist grossartig, oder?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_predictions(params, data, predict_func):\n",
    "    \"\"\"Computes the actual predictions. Allows for recovery in case of a crash...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: dict\n",
    "        The dictionary containing the parameters\n",
    "    data: dataframe\n",
    "        The data\n",
    "    predict_func: callable\n",
    "        The function that computes the prediction\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    from fhnw.nlp.utils.storage import save_dataframe\n",
    "    from fhnw.nlp.utils.storage import load_dataframe\n",
    "    \n",
    "    verbose = params.get(\"verbose\", False)\n",
    "    batch_size = params.get(\"batch_size\", 8)\n",
    "    X_column_name = params.get(\"X_column_name\", \"text\")\n",
    "    y_column_name = params.get(\"y_column_name\", \"label\")\n",
    "    y_column_name_prediction = params.get(\"y_column_name_prediction\", \"prediction\")\n",
    "    store_every_n_elements = params.get(\"store_every_n_elements\", 32768)\n",
    "    store_path = params.get(\"store_path\", \"data/predictions.parq\")\n",
    "    last_stored_batch = params.get(\"last_stored_batch\", -1)\n",
    "    empty_gpu_cache = params.get(\"empty_gpu_cache\", False)\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    # load stored data for recovery\n",
    "    if last_stored_batch >= 0 or last_stored_batch == -1 and os.path.exists(store_path):\n",
    "        predictions_loaded = load_dataframe(store_path)\n",
    "        predictions = [row.to_dict() for index, row in predictions_loaded.iterrows()]\n",
    "        \n",
    "        if last_stored_batch < 0:\n",
    "            last_stored_batch = len(predictions) // batch_size\n",
    "            \n",
    "        if verbose:\n",
    "            print(datetime.now().time(), \"Loaded batch:\", last_stored_batch, \" predictions: \", len(predictions))\n",
    "         \n",
    "    # do the predictions\n",
    "    for g, df in data.groupby(np.arange(len(data)) // batch_size):\n",
    "        if g >= last_stored_batch:\n",
    "            # prevent OOM on GPU\n",
    "            if empty_gpu_cache:\n",
    "                gpu_empty_cache()\n",
    "                \n",
    "            predictions_batch = predict_func(params, df[X_column_name].to_list())\n",
    "            \n",
    "            # store the predictions together with the data\n",
    "            i = 0\n",
    "            for index, row in df.iterrows():\n",
    "                # e.g. back translation might provide more than one translation per prediction\n",
    "                if isinstance(predictions_batch[i], list):\n",
    "                    for prediction in predictions_batch[i]:\n",
    "                        row_dict = row.to_dict()\n",
    "                        row_dict[y_column_name_prediction] = prediction\n",
    "                        predictions.append(row_dict)\n",
    "                else:\n",
    "                    row_dict = row.to_dict()\n",
    "                    row_dict[y_column_name_prediction] = predictions_batch[i]\n",
    "                    predictions.append(row_dict)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                \n",
    "            if (g + 1) % (store_every_n_elements // batch_size) == 0:\n",
    "                if verbose:\n",
    "                    print(datetime.now().time(), \"Save batch:\", str(g+1), \", processed elements:\", str((g+1)*batch_size), \", total predictions:\", len(predictions))\n",
    "\n",
    "                save_dataframe(pd.DataFrame(predictions), store_path)\n",
    "\n",
    "    if verbose:\n",
    "        print(datetime.now().time(), \"Prediction done. Batches:\", str(data.shape[0] // batch_size), \", processed elements:\", str(data.shape[0]), \", total predictions:\", len(predictions))\n",
    "    \n",
    "    pred_data = pd.DataFrame(predictions)\n",
    "    save_dataframe(pred_data, store_path)\n",
    "    \n",
    "    return pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:53:26.098258 Save batch: 4096 , processed elements: 32768 , total predictions: 130728\n",
      "01:55:59.910435 Prediction done. Batches: 4127 , processed elements: 33022 , total predictions: 131741\n",
      "CPU times: user 5h 31min 7s, sys: 38 s, total: 5h 31min 45s\n",
      "Wall time: 5h 22min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_augm_translated = compute_predictions(params, data_augm, back_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>dieser arzt ist die unmöglichste in meinem leb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>dieser arzt ist der unmöglichste in meinem leb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Dieser Arzt ist das unmöglichste was mir in me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>dieser arzt ist das unmöglichste, was sie je i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text_original  rating  \\\n",
       "0  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "2  Dieser Arzt ist das unmöglichste was mir in me...     6.0   \n",
       "\n",
       "                                                text     label  sentiment  \\\n",
       "0  Dieser Arzt ist das unmöglichste was mir in me...  negative         -1   \n",
       "1  Dieser Arzt ist das unmöglichste was mir in me...  negative         -1   \n",
       "2  Dieser Arzt ist das unmöglichste was mir in me...  negative         -1   \n",
       "\n",
       "                                         translation  \n",
       "0  dieser arzt ist die unmöglichste in meinem leb...  \n",
       "1  dieser arzt ist der unmöglichste in meinem leb...  \n",
       "2  dieser arzt ist das unmöglichste, was sie je i...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augm_translated.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe(data_augm_translated, \"data/german_doctor_reviews_augmented_translated_\"+lang_to+\".parq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
